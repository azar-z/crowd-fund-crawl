{
  "report_date": "2025-08-17T23:54:12.050691",
  "report_type": "llm_based_three_agent_scoring",
  "llm_model": "gemma-3-27b-it",
  "evaluation_method": "automated_llm_judgment",
  "overall_scores": {
    "basic_agent": {
      "agent_name": "Basic Agent",
      "correct": 239,
      "incorrect": 125,
      "evaluated": 364,
      "accuracy": 65.7,
      "overall_confidence": 0.928,
      "projects_count": 52
    },
    "function_agent": {
      "agent_name": "Function Agent",
      "correct": 251,
      "incorrect": 113,
      "evaluated": 364,
      "accuracy": 69.0,
      "overall_confidence": 0.928,
      "projects_count": 52
    },
    "expert_agent": {
      "agent_name": "Expert Agent",
      "correct": 301,
      "incorrect": 63,
      "evaluated": 364,
      "accuracy": 82.7,
      "overall_confidence": 0.928,
      "projects_count": 52
    }
  },
  "project_details": [
    {
      "project_name": "acometr",
      "evaluation_date": "2025-08-17T23:49:19.902938",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.857
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.857
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.857
        }
      }
    },
    {
      "project_name": "aticrowd",
      "evaluation_date": "2025-08-17T18:29:40.615228",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "atiyeiranian",
      "evaluation_date": "2025-08-17T19:57:24.722786",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "babaha",
      "evaluation_date": "2025-08-17T22:01:08.728729",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "bithome",
      "evaluation_date": "2025-08-17T23:49:50.113561",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "charisma",
      "evaluation_date": "2025-08-17T17:37:03.608835",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "dariccrowd",
      "evaluation_date": "2025-08-17T19:57:55.323030",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "dayancrowd",
      "evaluation_date": "2025-08-17T18:30:08.862633",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        }
      }
    },
    {
      "project_name": "dongi",
      "evaluation_date": "2025-08-17T15:03:20.907013",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "ebtekar",
      "evaluation_date": "2025-08-17T22:01:39.351241",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "fankamfund",
      "evaluation_date": "2025-08-17T22:03:03.559585",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "fundocrowd",
      "evaluation_date": "2025-08-17T19:14:33.840419",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "ghoghnoos",
      "evaluation_date": "2025-08-17T23:51:14.750953",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "gholakcrowd",
      "evaluation_date": "2025-08-17T22:03:28.733818",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "golrang",
      "evaluation_date": "2025-08-17T19:59:19.809098",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 1.0
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 1.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 1.0
        }
      }
    },
    {
      "project_name": "halalfund",
      "evaluation_date": "2025-08-17T14:59:38.846282",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamafarin",
      "evaluation_date": "2025-08-17T15:03:48.343850",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamashena",
      "evaluation_date": "2025-08-17T17:37:31.457161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    },
    {
      "project_name": "ibcrowd",
      "evaluation_date": "2025-08-17T23:51:42.531525",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "ideafund",
      "evaluation_date": "2025-08-17T19:59:45.266256",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "ifund",
      "evaluation_date": "2025-08-17T15:04:15.638036",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "investorun",
      "evaluation_date": "2025-08-17T22:04:51.993643",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.871
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.871
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.871
        }
      }
    },
    {
      "project_name": "isatiscrowd",
      "evaluation_date": "2025-08-17T20:01:08.871504",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "jahesh",
      "evaluation_date": "2025-08-17T23:03:18.212820",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "jamsepar",
      "evaluation_date": "2025-08-17T20:01:34.016451",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "karamad",
      "evaluation_date": "2025-08-17T20:01:58.931869",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.893
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.893
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.893
        }
      }
    },
    {
      "project_name": "karencrowd",
      "evaluation_date": "2025-08-17T15:05:40.719018",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "karmaye",
      "evaluation_date": "2025-08-17T22:05:20.477608",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.843
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.843
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.843
        }
      }
    },
    {
      "project_name": "khoonemetri",
      "evaluation_date": "2025-08-17T23:53:06.110154",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "maskanplus",
      "evaluation_date": "2025-08-17T15:06:08.132919",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.479
        },
        "function_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        },
        "expert_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        }
      }
    },
    {
      "project_name": "mobincrowd",
      "evaluation_date": "2025-08-17T15:06:32.762882",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "novincrowd",
      "evaluation_date": "2025-08-17T18:31:33.466067",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "expert_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        }
      }
    },
    {
      "project_name": "omid",
      "evaluation_date": "2025-08-17T22:05:45.577563",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.907
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.907
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.907
        }
      }
    },
    {
      "project_name": "opalcrowd",
      "evaluation_date": "2025-08-17T18:32:00.807161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.9
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.9
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.9
        }
      }
    },
    {
      "project_name": "paresh",
      "evaluation_date": "2025-08-17T18:33:25.439536",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "petrocrowd",
      "evaluation_date": "2025-08-17T22:07:12.554853",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "pishrun",
      "evaluation_date": "2025-08-17T23:03:43.911592",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "pulsar",
      "evaluation_date": "2025-08-17T15:07:58.541114",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.764
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        },
        "expert_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        }
      }
    },
    {
      "project_name": "rayan",
      "evaluation_date": "2025-08-17T17:38:54.816406",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "rayfund",
      "evaluation_date": "2025-08-17T20:03:25.668203",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "razavi",
      "evaluation_date": "2025-08-17T15:08:26.418425",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "sdcrowd",
      "evaluation_date": "2025-08-17T23:04:09.228654",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.907
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.907
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.907
        }
      }
    },
    {
      "project_name": "sepehrino",
      "evaluation_date": "2025-08-17T18:33:52.204108",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "shariffund",
      "evaluation_date": "2025-08-17T20:03:53.422594",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.871
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.871
        },
        "expert_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.871
        }
      }
    },
    {
      "project_name": "smartfunding",
      "evaluation_date": "2025-08-17T18:34:20.877616",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        }
      }
    },
    {
      "project_name": "startamin",
      "evaluation_date": "2025-08-17T17:39:23.272561",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "submelk",
      "evaluation_date": "2025-08-17T23:53:34.041778",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "vestacrowd",
      "evaluation_date": "2025-08-17T18:35:46.200006",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.836
        }
      }
    },
    {
      "project_name": "yektacrowd",
      "evaluation_date": "2025-08-17T20:05:22.298632",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "zarincrowd",
      "evaluation_date": "2025-08-17T17:39:48.260156",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "zeema",
      "evaluation_date": "2025-08-17T15:14:00.937109",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "zotch",
      "evaluation_date": "2025-08-17T18:36:13.313380",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    }
  ],
  "summary": {
    "total_projects": 52,
    "best_agent": "expert_agent",
    "avg_confidence_across_agents": 0.928
  },
  "comparison_note": "This report uses LLM-based automatic evaluation instead of human validation"
}