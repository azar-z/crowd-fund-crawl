{
  "report_date": "2025-08-17T19:15:26.309166",
  "report_type": "llm_based_three_agent_scoring",
  "llm_model": "gemma-3-27b-it",
  "evaluation_method": "automated_llm_judgment",
  "overall_scores": {
    "basic_agent": {
      "agent_name": "Basic Agent",
      "correct": 116,
      "incorrect": 59,
      "evaluated": 175,
      "accuracy": 66.3,
      "overall_confidence": 0.914,
      "projects_count": 25
    },
    "function_agent": {
      "agent_name": "Function Agent",
      "correct": 114,
      "incorrect": 61,
      "evaluated": 175,
      "accuracy": 65.1,
      "overall_confidence": 0.914,
      "projects_count": 25
    },
    "expert_agent": {
      "agent_name": "Expert Agent",
      "correct": 141,
      "incorrect": 34,
      "evaluated": 175,
      "accuracy": 80.6,
      "overall_confidence": 0.914,
      "projects_count": 25
    }
  },
  "project_details": [
    {
      "project_name": "aticrowd",
      "evaluation_date": "2025-08-17T18:29:40.615228",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "charisma",
      "evaluation_date": "2025-08-17T17:37:03.608835",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "dayancrowd",
      "evaluation_date": "2025-08-17T18:30:08.862633",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        }
      }
    },
    {
      "project_name": "dongi",
      "evaluation_date": "2025-08-17T15:03:20.907013",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "fundocrowd",
      "evaluation_date": "2025-08-17T19:14:33.840419",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "halalfund",
      "evaluation_date": "2025-08-17T14:59:38.846282",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamafarin",
      "evaluation_date": "2025-08-17T15:03:48.343850",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamashena",
      "evaluation_date": "2025-08-17T17:37:31.457161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    },
    {
      "project_name": "ifund",
      "evaluation_date": "2025-08-17T15:04:15.638036",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "karencrowd",
      "evaluation_date": "2025-08-17T15:05:40.719018",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "maskanplus",
      "evaluation_date": "2025-08-17T15:06:08.132919",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.479
        },
        "function_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        },
        "expert_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        }
      }
    },
    {
      "project_name": "mobincrowd",
      "evaluation_date": "2025-08-17T15:06:32.762882",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "novincrowd",
      "evaluation_date": "2025-08-17T18:31:33.466067",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "expert_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        }
      }
    },
    {
      "project_name": "opalcrowd",
      "evaluation_date": "2025-08-17T18:32:00.807161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.9
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.9
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.9
        }
      }
    },
    {
      "project_name": "paresh",
      "evaluation_date": "2025-08-17T18:33:25.439536",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "pulsar",
      "evaluation_date": "2025-08-17T15:07:58.541114",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.764
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        },
        "expert_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        }
      }
    },
    {
      "project_name": "rayan",
      "evaluation_date": "2025-08-17T17:38:54.816406",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "razavi",
      "evaluation_date": "2025-08-17T15:08:26.418425",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "sepehrino",
      "evaluation_date": "2025-08-17T18:33:52.204108",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "smartfunding",
      "evaluation_date": "2025-08-17T18:34:20.877616",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        }
      }
    },
    {
      "project_name": "startamin",
      "evaluation_date": "2025-08-17T17:39:23.272561",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "vestacrowd",
      "evaluation_date": "2025-08-17T18:35:46.200006",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.836
        }
      }
    },
    {
      "project_name": "zarincrowd",
      "evaluation_date": "2025-08-17T17:39:48.260156",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "zeema",
      "evaluation_date": "2025-08-17T15:14:00.937109",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "zotch",
      "evaluation_date": "2025-08-17T18:36:13.313380",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    }
  ],
  "summary": {
    "total_projects": 25,
    "best_agent": "expert_agent",
    "avg_confidence_across_agents": 0.914
  },
  "comparison_note": "This report uses LLM-based automatic evaluation instead of human validation"
}