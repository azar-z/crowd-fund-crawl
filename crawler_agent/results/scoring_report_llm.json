{
  "report_date": "2025-08-17T20:06:25.888117",
  "report_type": "llm_based_three_agent_scoring",
  "llm_model": "gemma-3-27b-it",
  "evaluation_method": "automated_llm_judgment",
  "overall_scores": {
    "basic_agent": {
      "agent_name": "Basic Agent",
      "correct": 164,
      "incorrect": 81,
      "evaluated": 245,
      "accuracy": 66.9,
      "overall_confidence": 0.925,
      "projects_count": 35
    },
    "function_agent": {
      "agent_name": "Function Agent",
      "correct": 171,
      "incorrect": 74,
      "evaluated": 245,
      "accuracy": 69.8,
      "overall_confidence": 0.925,
      "projects_count": 35
    },
    "expert_agent": {
      "agent_name": "Expert Agent",
      "correct": 199,
      "incorrect": 46,
      "evaluated": 245,
      "accuracy": 81.2,
      "overall_confidence": 0.925,
      "projects_count": 35
    }
  },
  "project_details": [
    {
      "project_name": "aticrowd",
      "evaluation_date": "2025-08-17T18:29:40.615228",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "atiyeiranian",
      "evaluation_date": "2025-08-17T19:57:24.722786",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "charisma",
      "evaluation_date": "2025-08-17T17:37:03.608835",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.971
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.971
        }
      }
    },
    {
      "project_name": "dariccrowd",
      "evaluation_date": "2025-08-17T19:57:55.323030",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "dayancrowd",
      "evaluation_date": "2025-08-17T18:30:08.862633",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.907
        }
      }
    },
    {
      "project_name": "dongi",
      "evaluation_date": "2025-08-17T15:03:20.907013",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "fundocrowd",
      "evaluation_date": "2025-08-17T19:14:33.840419",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "golrang",
      "evaluation_date": "2025-08-17T19:59:19.809098",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 1.0
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 1.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 1.0
        }
      }
    },
    {
      "project_name": "halalfund",
      "evaluation_date": "2025-08-17T14:59:38.846282",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamafarin",
      "evaluation_date": "2025-08-17T15:03:48.343850",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "hamashena",
      "evaluation_date": "2025-08-17T17:37:31.457161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    },
    {
      "project_name": "ideafund",
      "evaluation_date": "2025-08-17T19:59:45.266256",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "ifund",
      "evaluation_date": "2025-08-17T15:04:15.638036",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.921
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.921
        }
      }
    },
    {
      "project_name": "isatiscrowd",
      "evaluation_date": "2025-08-17T20:01:08.871504",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "jamsepar",
      "evaluation_date": "2025-08-17T20:01:34.016451",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "karamad",
      "evaluation_date": "2025-08-17T20:01:58.931869",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.893
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.893
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.893
        }
      }
    },
    {
      "project_name": "karencrowd",
      "evaluation_date": "2025-08-17T15:05:40.719018",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "maskanplus",
      "evaluation_date": "2025-08-17T15:06:08.132919",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.479
        },
        "function_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        },
        "expert_agent": {
          "correct": 1,
          "incorrect": 6,
          "evaluated": 7,
          "accuracy": 14.3,
          "average_confidence": 0.479
        }
      }
    },
    {
      "project_name": "mobincrowd",
      "evaluation_date": "2025-08-17T15:06:32.762882",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "novincrowd",
      "evaluation_date": "2025-08-17T18:31:33.466067",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        },
        "expert_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.85
        }
      }
    },
    {
      "project_name": "opalcrowd",
      "evaluation_date": "2025-08-17T18:32:00.807161",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.9
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.9
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.9
        }
      }
    },
    {
      "project_name": "paresh",
      "evaluation_date": "2025-08-17T18:33:25.439536",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "pulsar",
      "evaluation_date": "2025-08-17T15:07:58.541114",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.764
        },
        "function_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        },
        "expert_agent": {
          "correct": 4,
          "incorrect": 3,
          "evaluated": 7,
          "accuracy": 57.1,
          "average_confidence": 0.764
        }
      }
    },
    {
      "project_name": "rayan",
      "evaluation_date": "2025-08-17T17:38:54.816406",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "rayfund",
      "evaluation_date": "2025-08-17T20:03:25.668203",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.993
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.993
        }
      }
    },
    {
      "project_name": "razavi",
      "evaluation_date": "2025-08-17T15:08:26.418425",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.964
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.964
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.964
        }
      }
    },
    {
      "project_name": "sepehrino",
      "evaluation_date": "2025-08-17T18:33:52.204108",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "evaluated": 7,
          "accuracy": 0.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "shariffund",
      "evaluation_date": "2025-08-17T20:03:53.422594",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "evaluated": 7,
          "accuracy": 28.6,
          "average_confidence": 0.871
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.871
        },
        "expert_agent": {
          "correct": 3,
          "incorrect": 4,
          "evaluated": 7,
          "accuracy": 42.9,
          "average_confidence": 0.871
        }
      }
    },
    {
      "project_name": "smartfunding",
      "evaluation_date": "2025-08-17T18:34:20.877616",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.886
        }
      }
    },
    {
      "project_name": "startamin",
      "evaluation_date": "2025-08-17T17:39:23.272561",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.979
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.979
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.979
        }
      }
    },
    {
      "project_name": "vestacrowd",
      "evaluation_date": "2025-08-17T18:35:46.200006",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.836
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.836
        }
      }
    },
    {
      "project_name": "yektacrowd",
      "evaluation_date": "2025-08-17T20:05:22.298632",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "evaluated": 7,
          "accuracy": 100.0,
          "average_confidence": 0.986
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.986
        }
      }
    },
    {
      "project_name": "zarincrowd",
      "evaluation_date": "2025-08-17T17:39:48.260156",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.914
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.914
        }
      }
    },
    {
      "project_name": "zeema",
      "evaluation_date": "2025-08-17T15:14:00.937109",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.943
        },
        "expert_agent": {
          "correct": 5,
          "incorrect": 2,
          "evaluated": 7,
          "accuracy": 71.4,
          "average_confidence": 0.943
        }
      }
    },
    {
      "project_name": "zotch",
      "evaluation_date": "2025-08-17T18:36:13.313380",
      "llm_model": "gemma-3-27b-it",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "evaluated": 7,
          "accuracy": 85.7,
          "average_confidence": 0.929
        }
      }
    }
  ],
  "summary": {
    "total_projects": 35,
    "best_agent": "expert_agent",
    "avg_confidence_across_agents": 0.925
  },
  "comparison_note": "This report uses LLM-based automatic evaluation instead of human validation"
}