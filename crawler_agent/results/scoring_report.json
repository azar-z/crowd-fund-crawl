{
  "report_date": "2025-08-17T17:33:48.942097",
  "report_type": "three_agent_scoring",
  "overall_scores": {
    "basic_agent": {
      "agent_name": "Basic Agent",
      "correct": 77,
      "incorrect": 28,
      "skipped": 0,
      "evaluated": 105,
      "accuracy": 73.3,
      "projects_count": 15
    },
    "function_agent": {
      "agent_name": "Function Agent",
      "correct": 80,
      "incorrect": 25,
      "skipped": 0,
      "evaluated": 105,
      "accuracy": 76.2,
      "projects_count": 15
    },
    "expert_agent": {
      "agent_name": "Expert Agent",
      "correct": 99,
      "incorrect": 6,
      "skipped": 0,
      "evaluated": 105,
      "accuracy": 94.3,
      "projects_count": 15
    }
  },
  "project_details": [
    {
      "project_name": "charisma",
      "validation_date": "2025-08-17T17:27:39.946795",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        },
        "function_agent": {
          "correct": 0,
          "incorrect": 7,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 0.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "dongi",
      "validation_date": "2025-08-15T21:31:41.191296",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "halalfund",
      "validation_date": "2025-08-15T21:31:41.194302",
      "agents": {
        "basic_agent": {
          "correct": 3,
          "incorrect": 4,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 42.9
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "hamafarin",
      "validation_date": "2025-08-15T21:32:37.271267",
      "agents": {
        "basic_agent": {
          "correct": 4,
          "incorrect": 3,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 57.1
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "hamashena",
      "validation_date": "2025-08-17T17:28:51.993491",
      "agents": {
        "basic_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "ifund",
      "validation_date": "2025-08-15T21:33:03.321495",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "karencrowd",
      "validation_date": "2025-08-15T22:05:02.481818",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    },
    {
      "project_name": "maskanplus",
      "validation_date": "2025-08-15T21:33:47.563164",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "mobincrowd",
      "validation_date": "2025-08-15T21:33:47.564843",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    },
    {
      "project_name": "pulsar",
      "validation_date": "2025-08-15T21:33:50.267549",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "rayan",
      "validation_date": "2025-08-17T17:30:33.315663",
      "agents": {
        "basic_agent": {
          "correct": 2,
          "incorrect": 5,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 28.6
        },
        "function_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    },
    {
      "project_name": "razavi",
      "validation_date": "2025-08-15T21:34:03.699822",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 3,
          "incorrect": 4,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 42.9
        },
        "expert_agent": {
          "correct": 7,
          "incorrect": 0,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 100.0
        }
      }
    },
    {
      "project_name": "startamin",
      "validation_date": "2025-08-17T17:31:55.449798",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    },
    {
      "project_name": "zarincrowd",
      "validation_date": "2025-08-17T17:32:23.745787",
      "agents": {
        "basic_agent": {
          "correct": 5,
          "incorrect": 2,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 71.4
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    },
    {
      "project_name": "zeema",
      "validation_date": "2025-08-15T21:34:03.703044",
      "agents": {
        "basic_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "function_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        },
        "expert_agent": {
          "correct": 6,
          "incorrect": 1,
          "skipped": 0,
          "evaluated": 7,
          "accuracy": 85.7
        }
      }
    }
  ],
  "summary": {
    "total_projects": 15,
    "best_agent": "expert_agent"
  }
}