
\فصل{مرور کارهای پیشین}

استخراج ساختارمند اطلاعات از محتوای وب یک مسئله سنتی و پرچالش در علوم کامپیوتر است که با ظهور مدل‌های زبانی بزرگ، وارد مرحله جدیدی شده است. این فصل به مرور روندهای اصلی پژوهشی مرتبط با این پروژه می‌پردازد، از رویکردهای سنتی مبتنی بر الگو و یادگیری ماشین گرفته تا الگوواره‌های نوین مبتنی بر مدل زبانی بزرگ، فراخوانی تابع و ارزیابی خودکار.

\قسمت{رویکردهای سنتی در استخراج اطلاعات از وب}

پیش از ظهور مدل‌های زبانی بزرگ، استخراج اطلاعات از وب عمدتاً بر سه رویکرد استوار بود. یکی از جامع‌ترین بررسی‌ها در این زمینه توسط لاگاتا و همکاران انجام شده است \cite{laGatta2012web}. این رویکردها شامل سیستم‌های مبتنی بر قاعده و الگو بودند که از عبارات منظم یا مسیرهای \lr{XPath} برای شناسایی داده‌ها استفاده می‌کردند. این روش‌ها، که اغلب در قالب «پوشش‌دهنده»ها پیاده‌سازی می‌شدند، برای وب‌سایت‌هایی با ساختار ثابت دقیق و سریع بودند، اما در برابر تغییرات ساختاری وب‌سایت شکننده عمل می‌کردند. رویکرد دیگر، استفاده از یادگیری ماشین نظارت‌شده بود که در آن مدل‌هایی مانند میدان‌های تصادفی شرطی برای یادگیری الگوهای استخراج از روی داده‌های برچسب‌خورده به کار گرفته می‌شدند. چالش اصلی در اینجا، نیاز به حجم بالای داده‌های آموزشی باکیفیت بود. برای کاهش این هزینه، روش‌های یادگیری با نظارت ضعیف یا دور نیز توسعه یافتند که از منابع جانبی برای تولید خودکار داده‌های آموزشی پُرنویز استفاده می‌کردند.

\قسمت{تحول با مدل‌های زبانی بزرگ}

ظهور مدل‌های زبانی بزرگ، همانطور که در پیمایش جامع ژائو و همکاران تشریح شده است \cite{zhao2023survey}، الگوواره استخراج اطلاعات را متحول کرد. این مدل‌ها با توانایی درک عمیق زبان طبیعی و پیروی از دستورالعمل‌های پیچیده، امکان استخراج اطلاعات را بدون نیاز به آموزش خاص دامنه فراهم کردند. یکی از کلیدی‌ترین قابلیت‌های این مدل‌ها، توانایی تولید خروجی‌های ساختارمند مانند \lr{JSON} است. این قابلیت، نیاز به طراحی پوشش‌دهنده‌های پیچیده یا برچسب‌گذاری داده‌های انبوه را تا حد زیادی برطرف می‌کند.

\زیرقسمت{فراخوانی تابع}

فراخوانی تابع، که توسط شرکت \lr{OpenAI} به عنوان یک قابلیت کلیدی معرفی شد \cite{open2023function}، یک گام تکاملی مهم در استخراج ساختارمند با مدل‌های زبانی بزرگ است. در این رویکرد، به جای توصیف ساختار خروجی در پرامپت متنی، یک «ابزار» یا «تابع» با پارامترهای مشخص و نوع‌بندی‌شده به مدل معرفی می‌شود. مدل پس از تحلیل متن ورودی، این تابع را با مقادیر استخراج‌شده فراخوانی می‌کند. این مکانیزم پایایی خروجی را افزایش داده، احتمال توهم مدل را کاهش می‌دهد و اعتبارسنجی خودکار را تسهیل می‌کند. در این پروژه، عامل‌های تابع‌محور و متخصص از این قابلیت برای تضمین کیفیت و یکنواختی خروجی بهره می‌برند.

\قسمت{ارزیابی خودکار با مدل زبانی بزرگ به عنوان داور}

ارزیابی کیفیت سیستم‌های استخراج اطلاعات به طور سنتی نیازمند قضاوت انسانی است که فرآیندی کند و پرهزینه است. الگوواره «مدل زبانی بزرگ به عنوان داور» یک راهکار نوین برای این چالش است، که چانگ و همکاران در پیمایش خود به تفصیل به آن پرداخته‌اند \cite{chang2023survey}. در این رویکرد، یک مدل زبانی بزرگ و توانمند وظیفه مقایسه خروجی استخراج‌شده با متن منبع را بر عهده می‌گیرد و بر اساس یک معیار از پیش‌تعریف‌شده، درستی یا نادرستی آن را قضاوت می‌کند. با این حال، باید توجه داشت که این داور نیز ممکن است خطا کند. بنابراین، کالیبره کردن آن با استفاده از یک مجموعه داده طلایی که توسط انسان ارزیابی شده و محاسبه معیارهایی مانند ماتریس اغتشاش برای سنجش توافق بین دو داور، امری ضروری است.

\قسمت{جمع‌بندی}

این پروژه در تقاطع چندین حوزه پژوهشی قرار دارد. با بهره‌گیری از توانایی‌های نوین مدل‌های زبانی بزرگ در درک و ساختاردهی اطلاعات و ترکیب آن با تکنیک‌های مهندسی مانند پاک‌سازی داده و ارزیابی خودکار، یک راهکار جامع و عملی برای چالش استخراج اطلاعات از وب ارائه می‌دهد. معماری سه‌عاملی این پروژه نیز امکان بررسی موازنه بین سادگی، پایایی و دقت را فراهم می‌آورد و یک چارچوب آزمایشی غنی برای تحلیل عملکرد رویکردهای مختلف فراهم می‌کند.
