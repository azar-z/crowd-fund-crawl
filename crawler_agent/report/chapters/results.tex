
\فصل{نتایج}

در این فصل نتایج تجربی سامانه ارائه می‌شود. داده‌ها از گزارش‌های تولیدشده در شاخه \کد{results} استخراج شده‌اند.

\قسمت{کاهش توکن در گام پاک‌سازی}

با به‌کارگیری پاک‌سازی کارآمد \lr{HTML} در عامل متخصص، تعداد توکن‌های ورودی به مدل به‌صورت چشم‌گیری کاهش یافته است. بر اساس گزارش \کد{results/token_comparison.json}:

- \textbf{مجموع توکن خام (Basic)}: 2{,}921{,}762
- \textbf{مجموع توکن پس از پاک‌سازی (Expert)}: 765{,}006
- \textbf{کاهش کل}: 2{,}156{,}756 (\textbf{73.82\%})
- \textbf{میانگین توکن به‌ازای پروژه}: Basic ≈ 56{,}188 ، Expert ≈ 14{,}712

\قسمت{مقایسه سه عامل}

خلاصه دقت و زمان (گزارش \کد{results/scoring_report.json}):

\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\سیاه عامل & \سیاه دقت (\%) & \سیاه پروژه‌ها & \سیاه زمان میانگین (ثانیه) \\
\hline
Basic & 78.0 & 52 & 2.93 \\
Function & 76.9 & 52 & 2.06 \\
Expert & 90.9 & 52 & 7.59 \\
\hline
\end{tabular}
\end{center}

نکته: افزایش دقت عامل متخصص همراه با هزینه زمانی بیشتر حاصل شده است. در عوض، پاک‌سازی باعث کاهش چشم‌گیر توکن و کنترل هزینه می‌شود.

\قسمت{مصرف توکن به‌ازای عامل}

بر اساس \کد{results/token_comparison.json}، مجموع توکن‌های ورودی:

- Basic: 2{,}921{,}762 (میانگین \~56k)
- Expert: 765{,}006 (میانگین \~14.7k)

\متن‌سیاه{یادداشت}: مصرف توکن برای عامل \lr{Function} در نسخه فعلی گزارش توکنی ثبت نشده است.

\قسمت{تعداد درخواست‌ها}

در گزارش‌های موجود، تعداد درخواست‌های \lr{API} به‌صورت صریح ثبت نشده است؛ در صورت نیاز می‌توان ثبت‌گر سبک‌وزنی به لایه فراخوانی مدل افزود تا شمار درخواست‌ها در هر عامل/پروژه گزارش شود.

\قسمت{داوری LLM در مقایسه با انسان}

خلاصه کارایی LLM بر مبنای گزارش \کد{results/llm_judge_confusion_matrix_report.json} (تجمیع بر همه عوامل):

\begin{center}
\begin{tabular}{|l|c|}
\hline
\سیاه شاخص & \سیاه مقدار \\
\hline
TP & 763 \\
FP & 28 \\
TN & 169 \\
FN & 132 \\
Accuracy & 0.854 \\
Precision & 0.965 \\
Recall (TPR) & 0.853 \\
F1 & 0.905 \\
FPR & 0.142 \\
FNR & 0.148 \\
\hline
\end{tabular}
\end{center}

\قسمت{جمع‌بندی نتایج}

- عامل متخصص دقیق‌ترین نتایج را ارائه می‌دهد (\~91\% دقت)، با هزینه زمانی بیشتر.
- پاک‌سازی \lr{HTML} میانگین توکن ورودی را \textbf{بیش از 3.8 برابر} کاهش داده و هزینه را کوچک می‌کند.
- داور \lr{LLM} در مجموع \textbf{F1≈0.91} و \textbf{Accuracy≈0.85} در مقایسه با انسانی داشته است که برای پایش پیوسته مناسب است.
