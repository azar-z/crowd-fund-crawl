\فصل{بیان راه‌حل پیشنهادی}

در این فصل، جزئیات فنی پیاده‌سازی و معماری سامانه استخراج اطلاعات تشریح می‌شود. سامانه بر یک معماری عامل‌محور استوار است که توسط یک چارچوب ارزیابی جامع برای سنجش عملکرد پشتیبانی می‌شود.

\قسمت{معماری فنی و جزئیات پیاده‌سازی}

سامانه از دو بخش اصلی تشکیل شده است: هسته استخراج که وظیفه پردازش \lr{HTML} و استخراج داده را بر عهده دارد و چارچوب ارزیابی که برای سنجش و مقایسه نتایج به کار می‌رود.

\زیرقسمت{هسته استخراج: عامل‌های هوشمند}
سه عامل با راهبردهای متفاوت برای استخراج اطلاعات پیاده‌سازی شده‌اند تا امکان تحلیل موازنه‌های مختلف بین سرعت، دقت و پیچیدگی فراهم شود. الگوهای کامل پرامپت استفاده‌شده برای هر عامل در پیوست~\ref{appendix:prompts} آمده است.

\begin{itemize}
    \item \textbf{عامل پایه}: این عامل به عنوان خط مبنا عمل می‌کند و از یک پرامپت مستقیم (پیوست~\ref{appendix:prompts}) برای استخراج اطلاعات در قالب \lr{JSON} از \lr{HTML} خام بهره می‌برد. این روش فاقد مرحله پیش‌پردازش یا فراخوانی تابع است و سادگی را در اولویت قرار می‌دهد.

    \item \textbf{عامل تابع‌محور}: این عامل با بهره‌گیری از قابلیت فراخوانی تابع، ساختار داده مورد نظر را به عنوان یک تابع به مدل معرفی می‌کند تا خروجی ساختارمند و یکنواخت تضمین شود. پرامپت این عامل (پیوست~\ref{appendix:prompts}) بسیار مختصر است و تنها از مدل می‌خواهد که از تابع معرفی‌شده استفاده کند.

    \item \textbf{عامل متخصص}: این عامل از یک فرایند چندمرحله‌ای برای دستیابی به حداکثر دقت استفاده می‌کند که در ادامه به تفصیل تشریح می‌شود.
\end{itemize}

\زیرقسمت{جزئیات عملکرد عامل متخصص}
عامل متخصص برای دستیابی به بالاترین دقت، فرآیندی سه‌مرحله‌ای را طی می‌کند:

\paragraph{مرحله ۱: پاک‌سازی هوشمند \lr{HTML}}
اولین گام، آماده‌سازی محتوای \lr{HTML} برای پردازش بهینه توسط مدل زبانی است. این مرحله با هدف کاهش نویز و حجم داده ورودی، بدون از دست دادن اطلاعات کلیدی، انجام می‌شود. فرآیند پاک‌سازی شامل حذف کامل تگ‌های \lr{<script>} و \lr{<style>}، حذف کامنت‌های \lr{HTML}، حذف ویژگی‌های غیرضروری مانند \lr{class} و \lr{id} که صرفاً برای استایل‌دهی به کار می‌روند و در نهایت، نرمال‌سازی فضاهای خالی برای کاهش تعداد توکن‌های غیرضروری است. این کار نه تنها هزینه فراخوانی مدل را کاهش می‌دهد، بلکه با ارائه یک ورودی تمیزتر، به مدل کمک می‌کند تا بر روی محتوای معنایی تمرکز کند.

\paragraph{مرحله ۲: استخراج چندمرحله‌ای با پرامپت‌های متنوع}
به جای اتکا به یک بار استخراج، عامل متخصص سه دور استخراج مستقل را با استفاده از سه پرامپت متفاوت (که در پیوست~\ref{appendix:prompts} آمده‌اند) اجرا می‌کند. هر پرامپت با هدف خاصی طراحی شده است تا مدل را به تمرکز بر جنبه‌های متفاوتی از وظیفه وادارد و از این طریق، احتمال خطا را کاهش داده و جامعیت نتیجه را افزایش دهد. این راهبرد تضمین می‌کند که اگر اطلاعاتی در یک دور به دلیل پیچیدگی خاصی از دید مدل پنهان بماند، در دورهای بعدی با نگاهی متفاوت، شانس استخراج آن افزایش یابد.
\begin{itemize}
    \item \textbf{پرامپت دور اول (استخراج جامع)}: هدف این پرامپت، انجام یک برداشت اولیه و گسترده از اطلاعات است. دستورالعمل‌های آن عمومی هستند و مدل را تشویق می‌کنند تا تمام اطلاعات قابل استخراج را بدون سخت‌گیری بیش از حد پیدا کند. این مرحله مانند یک تور بزرگ عمل می‌کند که ممکن است جزئیاتی را از قلم بیندازد، اما تصویر کلی را به دست می‌آورد و تضمین می‌کند که مقادیر اولیه برای اکثر فیلدها شناسایی شوند.

    \item \textbf{پرامپت دور دوم (تأکید بر دقت و کامل بودن)}: این پرامپت مدل را به بازبینی دقیق‌تر و وسواس‌گونه‌تر وامی‌دارد. با استفاده از کلماتی مانند «با دقت» و «کامل»، به مدل گفته می‌شود که به جزئیات توجه کرده و از استخراج متن‌های خلاصه‌شده یا ناقص خودداری کند. این مرحله برای فیلدهایی که نیازمند متن کامل هستند (مانند بخش تضمین‌ها) یا مقادیری که ممکن است در نگاه اول ناقص دیده شوند، حیاتی است.

    \item \textbf{پرامپت دور سوم (چک‌لیست کیفیت)}: این پرامپت به عنوان یک مرحله بازبینی نهایی عمل می‌کند. با ارائه یک چک‌لیست صریح، مدل موظف می‌شود خروجی خود را بر اساس معیارهای کیفی مشخصی مانند پر بودن فیلدهای اجباری، کامل بودن متن‌ها و صحت واحد اعداد، اعتبارسنجی کند. این پرامپت، احتمال بروز خطاهای رایج مانند مقادیر خالی یا جایگزین را به حداقل می‌رساند و به نوعی مدل را به کنترل کیفیت خروجی خود وامی‌دارد.
\end{itemize}

\paragraph{مرحله ۳: ادغام هوشمند نتایج}
پس از اتمام سه دور استخراج، نتایج به دست آمده باید در یک خروجی واحد و بهینه تجمیع شوند. فرآیند ادغام هوشمند به این صورت عمل می‌کند که ابتدا استخراجی که بالاترین امتیاز اطمینان اولیه را دارد به عنوان نتیجه پایه در نظر گرفته می‌شود. سپس، این نتیجه پایه با نتایج دو دور دیگر مقایسه می‌شود. برای هر فیلد، اگر مقدار آن در نتیجه پایه خالی یا دارای نشانه‌های خطا (مانند \lr{null} یا \lr{not found}) باشد، با مقدار معتبر از دورهای دیگر جایگزین می‌شود. همچنین، اگر یک دور دیگر متنی طولانی‌تر و کامل‌تر برای یک فیلد متنی پیدا کرده باشد، آن مقدار جایگزین نسخه کوتاه‌تر می‌شود. این فرآیند تضمین می‌کند که خروجی نهایی، کامل‌ترین و صحیح‌ترین اطلاعات ممکن از مجموع سه دور استخراج را در خود جای داده است.

\زیرقسمت{روش‌شناسی ارزیابی}
داده‌های مورد استفاده در ارزیابی از سکوهای فعال تأمین مالی جمعی در ایران گردآوری شده‌اند. هر نمونه داده، صفحه وب توضیحات یک طرح واقعی در یکی از این سکوها است. عامل‌های طراحی‌شده، محتوای \lr{HTML} خام این صفحات را به عنوان ورودی دریافت می‌کنند و تلاش می‌کنند تا اطلاعات کلیدی طرح را در یک ساختار خروجی یکسان استخراج کنند. این ساختار شامل اطلاعاتی نظیر نام طرح، نام متقاضی، سود، مدت و وضعیت طرح است. جزئیات کامل ساختار خروجی مورد انتظار در پیوست~\ref{appendix:config_format} آمده است.

برای سنجش دقیق عملکرد عامل‌های استخراج، از یک روش‌شناسی ارزیابی دومرحله‌ای استفاده شده است که شامل ارزیابی انسانی به عنوان معیار اصلی و ارزیابی خودکار به عنوان یک پژوهش روش‌شناختی ثانویه است.

\paragraph{ارزیابی انسانی: حقیقت زمینه‌ای}
مبنای اصلی برای سنجش دقت عامل‌ها، ارزیابی دقیق توسط انسان است. برای این منظور، یک مجموعه داده تهیه شد. در این فرآیند، خروجی هر سه عامل برای تمام پروژه‌های مجموعه آزمایشی به صورت دستی بررسی و صحت هر فیلد استخراج‌شده تأیید یا رد گردید. این مجموعه داده برچسب‌خورده، به عنوان حقیقت زمینه‌ای عمل می‌کند و تمامی معیارهای عملکردی نهایی، از جمله امتیاز \lr{F1}، بر اساس مقایسه با آن محاسبه شده‌اند. این روش، با وجود زمان‌بر بودن، بالاترین سطح اطمینان را برای ارزیابی عملکرد واقعی عامل‌ها فراهم می‌کند.

\paragraph{ارزیابی خودکار: سنجش کارایی الگوواره داور خودکار}
به عنوان یک هدف پژوهشی ثانویه، این تحقیق به بررسی کارایی و قابلیت اطمینان الگوواره «مدل زبانی بزرگ به عنوان داور» پرداخت. در این راستا، یک داور خودکار با استفاده از مدل \lr{Gemma-3-27b-it} پیاده‌سازی شد. وظیفه این داور، مقایسه خودکار خروجی عامل‌ها با پاسخ‌های صحیح از پیش تعیین‌شده و قضاوت در مورد صحت آن‌ها بود. هدف از این بخش، ارزیابی این موضوع بود که آیا می‌توان از یک داور خودکار به عنوان جایگزینی مقیاس‌پذیر برای داوری انسانی در پژوهش‌های آینده استفاده کرد یا خیر. نتایج عملکرد این داور، که در فصل نتایج ارائه شده است، از طریق مقایسه قضاوت‌های آن با حقیقت زمینه‌ای (یعنی داوری انسانی) به دست آمده است تا میزان توافق و قابلیت اطمینان آن به صورت کمی سنجیده شود.
